* Transaction relay

** Concepts and purpose

*** Transaction relay

- Transaction relay :: The transaction relay process propagates new signed and
  validated transaction through the peer-to-peer network of blockchain nodes.
  Every node participates in the transaction relay process by receiving new
  transactions, validating transactions against the pending state of the node
  and forwarding valid transactions to the list of known peers of the node.
  There are two cases where the transaction relay process takes place
  - Transaction sign, send, validate, and relay :: New transactions are first
    submitted by a client to the node for signing, and then sent by a client to
    the node for validation through transaction application to the node's
    pending state. Any transaction application errors are directly returned to
    the client. After the successful transaction application the transaction is
    considered valid and is relayed to the node's list of known peers. The
    transaction sign, send, validated, and relay process ensures that only
    validated transactions are relayed to the list of known peers. Reception of
    an already applied transaction results in an transaction application error,
    and the duplicated transaction is not relayed any more. This protects the
    blockchain network from relaying already relayed transactions
  - Transaction receive, validate and relay :: Transactions signed and sent to
    other nodes are relayed to the node through the transaction received,
    validate, and relay mechanism. The node receives a transaction, applies the
    transaction to the pending state and, if valid, relays the transaction to
    the list of known peers. Once again, application of an already applied
    transaction to the pending state results in an error, and the duplicated
    transaction is not relayed any more

** Design and implementation

*** The message relay type

- Message relay type :: The =MsgRelay= type reliably handles propagation of
  validated transaction an blocks through the peer-to-peer network of the
  blockchain. The message relay takes messages from where they are created and
  validated and forwards messages to where they are processed and confirmed. The
  message relay component is fully integrated in the node graceful shutdown
  mechanism. The node shared context hierarchy is used to signal graceful
  shutdown of all concurrent processes on the node including the message relay.
  On reception of the shutdown signal the message relay finishes relaying
  messages in progress and gracefully shuts down. The main node's goroutine
  gives time to all concurrent processes to shutdown correctly by waiting on the
  shared wait group. The inbound message channel is exposed to transaction and
  block creation and forwarding components to receive new messages in the
  concurrency safe way. All transaction- and block-specific gRPC logic is
  encapsulated and parameterized in the gRPC relay function. The message relay
  supports self-relaying messages to the node itself through the self relay
  configuration parameter. The message relay periodically monitors the list of
  known peer for new peer to start relaying messages to the new peers. The
  message relay gracefully shuts down all goroutines dedicated to relaying
  messages to known peers by waiting on the relays wait group after the know
  shared context hierarchy has been canceled. The peer add and peer remove
  channels ensure concurrency safe addition of new discovered peers and disposal
  of closed peers while reliably relaying messages to known healthy peers
  - Generic message relay type :: The =MsgRelay= type is a generic type that
    handles relay of both transactions and blocks in the peer-to-peer network of
    the blockchain. The message relay type is parameterized with the message
    type to relay transaction and blocks and the gRPC relay function to manage
    the corresponding gRPC client stream of transactions or blocks. This design
    provides a flexible and resilient message relay, while reusing robust
    implementation of the common concurrent relay logic without code duplication
    that would be required if the message relay type were not generic.
  - Concurrency safe message relay type :: The message relay type is concurrency
    safe. The concurrency safety of the message relay type is achieved through
    the use of channels. A single inbound message channel exposed to the
    transaction sign, send, validate, and relay component, the transaction
    receive, validate, and relay component. The inbound message channel receives
    new or relayed validated transactions to be further relayed to the node's
    list of known peers. The transaction relay to the list of known peers is
    implemented by multiplexing the inbound message channel over the list of
    outbound channels each with a dedicated goroutine representing for every
    peer from the list of known peers of the node. This design ensures
    concurrent relay of messages without blocking know peers down the list if
    there is a problem with a peer at the top of the list. The relay of message
    in fully concurrent on the bases of every known peer. Problems with relaying
    messages to one peer does not impact message relay to other peers
  - Concurrent peer discovery and disposition of closed connections :: The
    message relay periodically checks the node's list of known peers for new
    discovered peers to be included into the message relay list of peers. When a
    new peer is discovered a dedicated outbound channel is created with an
    associated goroutine to forward relayed messages from the inbound message
    channel to the new peer. After an error, the connection is gracefully closed
    including the dedicated outbound channel and the associated goroutine. This
    design contributes to the resilience of the message relay as new peers are
    progressively added to the list message relay, while problematic peers are
    gracefully closed and disposed in the concurrency safe way
  - gRPC client streaming for message relay :: This implementation uses the gRPC
    client streaming to relay messages to every known peer. This design
    naturally forwards a stream of new transactions to every peer with minimal
    network overhead. A separate client stream gRPC connection is established
    with every known peer and is reused until there is an error in the
    connection e.g. the peer node goes offline
  | ~ctx context.Context~              | Node shared context hierarchy   |
  | ~wg *sync.WaitGroup~               | Node shared wait group          |
  | ~chMsg chan Msg~                   | Inbound generic message channel |
  | ~grpcRelay Relay~                  | gRPC generic client streaming   |
  | ~selfRelay bool~                   | Self-relay configuration option |
  | ~peerReader PeerReader~            | Peer reader                     |
  | ~wgRelays *sync.WaitGroup~         | Relay wait group                |
  | ~chPeerAdd, chPeerRem chan string~ | Peer add and remove channels    |
  #+BEGIN_SRC go
type MsgRelay[Msg any, Relay GRPCMsgRelay[Msg]] struct {
  ctx context.Context
  wg *sync.WaitGroup
  chMsg chan Msg
  grpcRelay Relay
  selfRelay bool
  peerReader PeerReader
  wgRelays *sync.WaitGroup
  chPeerAdd, chPeerRem chan string
}

func NewMsgRelay[Msg any, Relay GRPCMsgRelay[Msg]](
  ctx context.Context, wg *sync.WaitGroup, cap int,
  grpcRelay Relay, selfRelay bool, peerReader PeerReader,
) *MsgRelay[Msg, Relay] {
  return &MsgRelay[Msg, Relay]{
    ctx: ctx, wg: wg, chMsg: make(chan Msg, cap),
    grpcRelay: grpcRelay, selfRelay: selfRelay, peerReader: peerReader,
    wgRelays: new(sync.WaitGroup),
    chPeerAdd: make(chan string), chPeerRem: make(chan string),
  }
}
  #+END_SRC

*** Transaction relayer and block relayer interfaces

The message relay exposes the single inbound channel to relay messages. The
message relay for transactions and blocks happens through the =TxRelayer= and
the =BlockRelayer= interfaces. These interfaces are implemented by the
=MsgRelay= type. Places where the relayer interfaces are used
- The transaction relayer interface is used by the =TxSend= and =TxReceive=
  methods of the =Tx= gRPC service
- The block relayer interface is used by the =ProposeBlocks= method of the
  =BlockProposer= type and by the =BlockReceive= method of the =Block= gRPC
  service

#+BEGIN_SRC go
type TxRelayer interface {
  RelayTx(tx chain.SigTx)
}

type BlockRelayer interface {
  RelayBlock(blk chain.SigBlock)
}

func (r *MsgRelay[Msg, Relay]) RelayTx(tx Msg) {
  r.chMsg <- tx
}

func (r *MsgRelay[Msg, Relay]) RelayBlock(blk Msg) {
  r.chMsg <- blk
}
#+END_SRC

*** The message relay algorithm

- Message relay algorithm :: The message relay algorithm coordinates concurrent
  processes of monitoring new discovered peers through the peer reader
  interface, adding new peers for the message relay, removing offline peer from
  the message relay, multiplexing the inbound message channel over the list of
  message relay peers. The message relay algorithm starts a dedicated goroutine
  to periodically read all known peers of the node. Each new peer is handled by
  the peer add channel. If the peer is not in the list of message relay peers, A
  new outbound message relay channel is created with an associated goroutine to
  independently manage the message relay to the peer. A failure in communication
  with a peer causes the failed peer to be handled by the peer remove channel.
  The outbound message relay channel for the peer is closed, the associated
  goroutine is terminated. Later the same peer, when online again, will be
  handled by the peer add channel. Finally all messages from the inbound message
  relay channel are multiplexed to all active outbound message relay channels.
  The message relay algorithm is fully integrated in the node graceful shutdown
  mechanism by monitoring the cancellation of the node shared context hierarchy,
  waiting for all message relay goroutines to gracefully shutdown through the
  relay wait group, and notifying the graceful shutdown of the message relay to
  the node through the node shared wait group. The message relay algorithm
  - Start a goroutine for monitoring the list of known peers
  - Compose the channels for the node context cancellation, addition of new
    peers, removal of closed peers, relay of messages by multiplexing the
    inbound message relay channel to the list of outbound message relay channels
    - When the node shared context hierarchy is closed, close all active
      outbound message relay channels, wait for all active message relay
      goroutines to terminate and stop the message relay
    - When a new peer is discovered, create a new outbound message relay
      channel, start a new goroutine to handle the message relay to the peer
    - When an active peer is closed, close the outbound message relay channel,
      which causes the associated message relay goroutine to terminate
    - When a new message is sent to the inbound message relay channel, multiplex
      the message over the list of active outbound message relay channels, so
      the gRPC client streaming happens concurrently to all known active peers
  #+BEGIN_SRC go
func (r *MsgRelay[Msg, Relay]) RelayMsgs(period time.Duration) {
  defer r.wg.Done()
  r.wgRelays.Add(1)
  go r.addPeers(period)
  chRelays := make(map[string]chan Msg)
  closeRelays := func() {
    for _, chRelay := range chRelays {
      close(chRelay)
    }
  }
  for {
    select {
    case <- r.ctx.Done():
      closeRelays()
      r.wgRelays.Wait()
      return
    case peer := <- r.chPeerAdd:
      _, exist := chRelays[peer]
      if exist {
        continue
      }
      if r.selfRelay {
        fmt.Printf("<=> Blk relay: %v\n", peer)
      } else {
        fmt.Printf("<=> Tx relay: %v\n", peer)
      }
      chRelay := r.peerRelay(peer)
      chRelays[peer] = chRelay
    case peer := <- r.chPeerRem:
      _, exist := chRelays[peer]
      if !exist {
        continue
      }
      chRelay := chRelays[peer]
      close(chRelay)
      delete(chRelays, peer)
    case msg := <- r.chMsg:
      for _, chRelay := range chRelays {
        chRelay <- msg
      }
    }
  }
}
  #+END_SRC

*** Concurrent monitoring of new peers

- Peers monitoring :: The peers monitoring process is concurrently started by
  the message relay in order to keep relaying messages to new peers discovered
  over time. The peers monitoring happens periodically through the =PeerReader=
  interface. The peers monitoring process is fully integrated into the node
  graceful shutdown mechanism. In each peers monitoring cycle the list of known
  peers is sent to the peer add channel. Only new peers will result in creation
  of the new outbound message relay channel with the associated goroutine. Based
  on the value of the self relay configuration parameter either only known peers
  or known peers the the node's own address are sent to the peer add channel.
  The peers monitoring process
  - Periodically read the list of known peers with or without the node's own
    address
  - Send all known peers to the peer add channel
  #+BEGIN_SRC go
func (r *MsgRelay[Msg, Relay]) addPeers(period time.Duration) {
  defer r.wgRelays.Done()
  tick := time.NewTicker(period)
  defer tick.Stop()
  for {
    select {
    case <- r.ctx.Done():
      return
    case <- tick.C:
      var peers []string
      if r.selfRelay {
        peers = r.peerReader.SelfPeers()
      } else {
        peers = r.peerReader.Peers()
      }
      for _, peer := range peers {
        r.chPeerAdd <- peer
      }
    }
  }
}
  #+END_SRC

*** Outbound message relay through the gRPC client stream

- Outbound message relay :: The outbound message relay happens through a
  dedicated to the peer channel in the associated goroutine. This design allows
  to increase throughput of relayed messages by handling concurrently message
  relay to every active peer, increase resilience by isolating message relay in
  a dedicated goroutine on the per peer basis. The message relay goroutines are
  integrated into the message relay graceful shutdown mechanism through the node
  shared context hierarchy and the dedicated relay wait group. The outbound
  message relay creates a gRPC client connection with the peer and handles the
  node shared context, the gRPC client connection and the outbound message relay
  channel to the generic gRPC relay function that manages the gRPC client stream
  of relayed messages. On any error establishing the gRPC client connection of
  handling the gRPC client stream the peer is sent to the peer remove channel.
  This mark the peer as inactive, closes the channel, and terminates the
  associated goroutine. The outbound message relay process
  - Starts a dedicated to the peer message relay goroutine
  - The goroutine established the gRPC client connection with the peer
  - The goroutine handles the node shared context, the gRPC client connection,
    and the outbound message relay channel to the generic gRPC relay function
  #+BEGIN_SRC go
func (r *MsgRelay[Msg, Relay]) peerRelay(peer string) chan Msg {
  chRelay := make(chan Msg)
  r.wgRelays.Add(1)
  go func () {
    defer r.wgRelays.Done()
    conn, err := grpc.NewClient(
      peer, grpc.WithTransportCredentials(insecure.NewCredentials()),
    )
    if err != nil {
      fmt.Println(err)
      r.chPeerRem <- peer
      return
    }
    defer conn.Close()
    err = r.grpcRelay(r.ctx, conn, chRelay)
    if err != nil {
      fmt.Println(err)
      r.chPeerRem <- peer
      return
    }
  }()
  return chRelay
}
  #+END_SRC

- gRPC client streaming :: The gRPC client streaming relays messages from the
  outbound message relay channel to the gRPC client stream of messages. The gRPC
  client streaming is message type specific and is parameterized in the message
  relay type with the gRPC relay generic function. The gRPC relay generic
  function accepts the node shared context hierarchy, the gRPC client connection
  and the outbound message relay channel. The gRPC client streaming creates the
  message-specific gRPC clients and establishes the gRPC client stream. The gRPC
  client streaming combines the node shared context cancellation channel for
  graceful shutdown with the outbound message relay channel for streaming
  messages to the peer. When a new message is sent to the outbound message relay
  channel, the message is encoded and sent over the gRPC client stream to the
  peer. The gRPC client streaming
  - Create the message-specific gRPC client
  - Establish the gRPC client stream by calling the gRPC =TxReceive= method
  - Combine the node shared context hierarchy channel with the outbound message
    relay channel
    - When the node shared context hierarchy is canceled, close the gRPC client
      connection and stop the message relay for the peer
    - When a new message is sent to the outbound message relay channel, forward
      the message to the established gRPC client stream
  #+BEGIN_SRC go
type GRPCMsgRelay[Msg any] func(
  ctx context.Context, conn *grpc.ClientConn, chRelay chan Msg,
) error

var GRPCTxRelay GRPCMsgRelay[chain.SigTx] = func(
  ctx context.Context, conn *grpc.ClientConn, chRelay chan chain.SigTx,
) error {
  cln := rpc.NewTxClient(conn)
  stream, err := cln.TxReceive(context.Background())
  if err != nil {
    return err
  }
  defer stream.CloseAndRecv()
  for {
    select {
    case <- ctx.Done():
      return nil
    case tx, open := <- chRelay:
      if !open {
        return nil
      }
      jtx, err := json.Marshal(tx)
      if err != nil {
        fmt.Println(err)
        continue
      }
      req := &rpc.TxReceiveReq{Tx: jtx}
      err = stream.Send(req)
      if err != nil {
        fmt.Println(err)
        continue
      }
    }
  }
}
  #+END_SRC

*** gRPC =TxReceive= method

The gRPC =Tx= service provides the =TxReceive= method to receive transactions
relayed from the peer-to-peer network of the blockchain. The transaction relay
happens from the gRPC =TxSend= method and from the gRPC =TxReceive= method to
further relay validated transactions to other peers. The interface of the
service
#+BEGIN_SRC protobuf
message TxReceiveReq {
  bytes Tx = 1;
}

message TxReceiveRes { }

service Tx {
  rpc TxReceive(stream TxReceiveReq) returns (TxReceiveRes);
}
#+END_SRC

The implementation of the =TxReceive= method
- For each transaction received from the gRPC client stream
  - Decode the transaction
  - Apply the decoded transaction to the pending state, if successful,
  - Relay the validated transaction to the list of known peers
#+BEGIN_SRC go
func (s *TxSrv) TxReceive(
  stream grpc.ClientStreamingServer[TxReceiveReq, TxReceiveRes],
) error {
  for {
    req, err := stream.Recv()
    if err == io.EOF {
      res := &TxReceiveRes{}
      return stream.SendAndClose(res)
    }
    if err != nil {
      return err
    }
    var tx chain.SigTx
    err = json.Unmarshal(req.Tx, &tx)
    if err != nil {
      fmt.Println(err)
      continue
    }
    fmt.Printf("<== Tx receive\n%v\n", tx)
    err = s.txApplier.ApplyTx(tx)
    if err != nil {
      fmt.Print(err)
      continue
    }
    if s.txRelayer != nil {
      s.txRelayer.RelayTx(tx)
    }
  }
}
#+END_SRC

** Testing and usage

*** Testing gRPC =TxReceive= method

The =TestTxReceive= testing process
- Create and persist the genesis
- Create the state from the genesis
- Look up the initial owner account and balance from the genesis
- Re-create the initial owner account from the genesis
- Set up the gRPC server and gRPC client connection
- For each transaction
  - Create and sign a transaction
  - Encode the signed transaction
  - Call the gRPC =TxReceive= method
  - Wait for the transaction to be received and processed
- Verify the correct pending balance after receiving the transactions
#+BEGIN_SRC fish
go test -v -cover -coverprofile=coverage.cov ./... -run TxReceive
#+END_SRC

*** Testing transaction relay

The =TestTxRelay= testing process
- Set up the bootstrap node
  - Create the peer discovery without starting for the bootstrap node
  - Initialize the state on the bootstrap node by creating the genesis
  - Create and start the transaction relay for the bootstrap node
  - Start the gRPC server on the bootstrap node
- Set up the new node
  - Create and start the peer discovery for the new node
  - Wait for the peer discovery to discover peers
  - Synchronize the state on the new node by fetching the genesis and confirmed
    blocks from the bootstrap node
  - Start the gRPC server on the new node
  - Wait for the gRPC server of the new node to start
- Get the initial owner account and its balance from the genesis
- Re-create the initial owner account from the genesis
- Sign and send several signed transactions to the bootstrap node
- Verify that the initial account balance on the pending states of the new node
  and the bootstrap node are equal
#+BEGIN_SRC fish
go test -v -cover -coverprofile=coverage.cov ./... -run TxRelay
#+END_SRC
